---
title             : "The N400's 3 As: Association, Automaticity, Attenuation (and Some Semantics Too)"
shorttitle        : "N400 Association Attenuation"

author: 
  - name          : "Erin M. Buchanan"
    affiliation   : "1"
    corresponding : yes 
    address       : "901 S National, Springfield, MO, 65897"
    email         : "erinbuchanan@missouristate.edu"
  - name          : "John E. Scofield"
    affiliation   : "2"
  - name          : "Nathan Nunley"
    affiliation   : "3"

affiliation:
  - id            : "1"
    institution   : "Missouri State University"
  - id            : "2"
    institution   : "University of Missouri"
  - id            : "3"
    institution   : "University of Mississippi"

author_note: >
  Erin M. Buchanan, Department of Psychology, Missouri State University; John E. Scofield, Department of Psychology, University of Missouri, Columbia, MO, 65211; Nathan Nunley, University of Mississippi, P.O. Box 1848, University, MS, 28677.

abstract: >
  The N400 waveform carries new insight into the nature of linguistic processing and may shed light into the automaticity of priming word relationships. We investigated semantic and associative word pairs in classic lexical decision and letter search tasks to examine their differences in cognitive processing. Normed database information was used to create orthogonal semantic and associative word relationships to clearly define N400 waveforms and priming for these pairs. Participants showed N400 reduction for related word pairs, both semantic and associative, in comparison to unrelated word pairs. This finding was consistent across both lexical decision and letter search tasks, indicating automatic access for both types of relatedness. Non-word pairs showed N400 waveforms that resembled unrelated word pairs, indicating the controlled examination of non-advantageous words. Response latency data nearly mirrored the EEG finding. Priming was found for semantic and associative word relationships, while non-word pairs were generally slower than unrelated word pairs.
  
keywords          : "association, semantics, priming, N400, EEG, lexical decision, letter search"

bibliography      : ["r-references.bib", "eeg refs.bib"]

figsintext        : no
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes

lang              : "english"
class             : "man"
output            : papaja::apa6_pdf
replace_ampersands: yes
csl               : apa6.csl
---

```{r libraries, include = FALSE}
knitr::opts_chunk$set(cache = TRUE)
library("papaja")
options(scipen=999)
library(nlme)
library(reshape)
library(ggplot2)
library(cowplot)
theme = theme(panel.grid.major = element_blank(), 
              panel.grid.minor = element_blank(), 
              panel.background = element_blank(), 
              axis.line.x = element_line(colour = "black"), 
              axis.line.y = element_line(colour = "black"), 
              legend.key = element_rect(fill = "white"),
              text = element_text(size = 15),
              legend.position='none',
              plot.margin = unit(c(0.3,1,0.3,0.3),'cm'))
```

Semantic facilitation through priming occurs when a related cue word speeds the processing of a following target word [@Meyer1971]. For example, if a person is reading about a yacht race, the word boat is easier to process because of previous activation in semantic memory. Research suggests that priming transpires by both automatic and controlled processes. The automatic model proposes that related words are linked in the brain due to overlapping features [@Collins1975]. Target words are activated without conscious control due to automatic spreading activation within related cognitive networks. Lexical and feature networks are thought to be stored separately, so that semantic priming is the activation from the feature network feeding back into the lexical level [@Stolz1996a]. The overlap of a second word's semantic relatedness makes word recognition easier because it, in essence, has already been processed. The controlled process model proposes that people actively use cognitive strategies to connect related words together. @Neely1991 describes both expectancy generation and post lexical matching as ways that target word processing may be speeded. In expectancy generation, people consciously attempt to predict the words and ideas that will appear next, especially in sentences. Whereas in post lexical matching, people delay processing of the second target word so that it can be compared to the cue word for evaluation. In both cases, the target word is quickened by its relationship to the cue word.
  
  Traditionally, priming has been tested with a simple word or nonword decision called a lexical decision task. Participants are shown a cue or priming word, followed by a related or unrelated target word for the word/nonword judgment. Priming occurs when the judgment for the target is speeded for related pairs over unrelated pairs. Lexical decision tasks have been criticized for their inability to distinguish between automatic and controlled processing, so both single presentation lexical decision tasks and masked priming manipulations  have been introduced to negate controlled processing [@Ford1983]. In a single lexical decision task, participants assess both the cue and target word so that they are not as overtly paired together. Experimenters might also mask or distort the cue word, so that participants do not believe they can perceive the cue word. Even though words are garbled, word perception occurs at a subliminal level and often facilitates the target word with automatic activation. 
  
##Priming in the Brain
  Event related potentials (ERPs) are used to distinguish both the nature of priming and the automaticity of priming. The use of ERPs is advantageous, measuring brain activity per an electroencephalogram (EEG) with good temporal resolution, and is thought to be a sensitive measure of real-time language processing [@Kutas2000]. The  N400 is a negative waveform that occurs 400 msec after the participant is presented with a stimulus [@Brown1993]. The N400 has been described as a 'contextual integration process', in which meanings of words are integrated and functions, bridging together sensory information and meaningful representations [@Kutas2000]. The amplitude of the N400 is sensitive to contextual word presentations, varying systematically with semantic processing. This change justifies the use of the N400 as an appropriate dependent measure for lexical decision tasks. When presented with related words, there is an attenuation of the N400, meaning a more positive waveform when compared to unrelated word presentation. This difference in waveforms indicates a lessened contextual integration process because word meanings are already activated.
  
Multiple theories of the N400, however, have been proposed and debated on what explicitly the N400 indexes. On one hand, processes associated with the N400 are believed to occur post-word recognition. @Brown1993 examined a lexical decision task paired with masked priming. No differences were found in the N400 wave between related and unrelated words in the masked prime condition. @Brown1993 concluded that this finding indicated that semantic activation was a controlled process, because attenuation only occurred when words were known. Thus, an 'integrating' process transpires with semantic information from of multi-word characteristic representations [@Kutas2011; @Hagoort2009]. This condition supposedly rules out automatic processes, because the masked prime condition only allowed automatic processes to take place. Masked priming did not allow the participants to consciously name the prime words they had seen; thus, they were not able to purposefully employ conscious cognitive strategies in processing these words. However, @Deacon2000 have found that with shorter stimulus onset asynchronies (SOAs), this effect of masked priming disappears. SOAs are the time interval between the prime word presentation and the target word appearance. Short SOAs are thought to only allow for automatic processing because the controlled, attention based processing has not had time yet to occur. Their study showed the masked primes long enough to enhance priming, while remaining imperceptible. With these modifications, @Deacon2004 found equal N400 attenuation for the masked and unmasked primes. This result would indicate that automatic activation was taking place, as the masked prime condition did not allow controlled processes to take place. @Kiefer2002 has found similar results in the N400 using different masking levels, which kept judgment ability of prime words below chance. 
  
A separate theory suggests that N400 effects are seen pre-word recognition. The N400 was found to be sensitive to pseudo- or non-words, even when absent a resemblance to real word counterparts. @Deacon2004 explain that this result could imply processes that precede word recognition, such as orthographic or phonological analysis. More recently, @Federmeier2009 suggested that the N400 indexes access to semantic memory. Meaningful stimuli representing a multitude of modalities indicates a sensitivity with attention, albeit still can occur in its absence. Processing from modalities can integrate, yielding different meanings from different contexts, respectively [@Federmeier2009]. Regardless of competing aspects as to what the N400 is estimated to index, vital insights have been made crossing different cognitive domains, with the N400 illuminating aspects originating from these different domains [@Kutas2011]. 
  
@Rolke2001 used the attention blink rapid serial visual presentation (RSVP) paradigm, in which participants identified target words within a stream of distractor words presented in a different color. By selecting items via specifying the row and column within a matrix, participants identified the target word they had previously seen. These studies compare to masked priming, and show automatic activation of semantic information even when targets were missed [@Rolke2001]. Letter search tasks also  reduce semantic priming by focusing attention on the lexical level instead of a feature meaning level [@Friedrich1991]. In this task, participants are asked to determine if cue and target words contain a specific letter presented. @Stolz1996a stipulate that this eliminated or reduced priming indicates non-automatic semantic priming. However, it is also important to note that @Tse2007 did yield evidence that letter search primes produced semantic priming for low-frequency targets, albeit not for high-frequency targets. In @Smith2001 letter search and lexical decision combined study, they found that the letter search task eliminated semantic priming when compared to unrelated word pairs and the lexical decision task. Yet, @Mari-Beffa2005 found ERP evidence for semantic processing of the prime word during letter search tasks with the attenuation of the N400.
  
##Association

From a theoretical standpoint, the relation between associative and semantic processing follows a deep line of research. Associative word pairs are words that are linked in one's memory by contextual relationships, such as basket and picnic [@Nelson2004]. Another example would be a word pair like alien and predator, which would be associatively linked for Americans due to the movies and popular culture. Semantic word pairs are those linked by their shared features and meaning, such as *wasp* and *bee* [@Buchanan2013; @McRae2005; @Vinson2008].
  
Associative and semantic relationships between words are experimentally definable by the use of normed databases. @Maki2004 took the online dictionary, WordNet [@Felbaum1998], and used software by @Patwardhan2003 to create a database of words displaying the semantic distance between individual words. This database displays the relatedness between two words by measuring how semantically close words appear in hierarchy, or the JCN [@Jiang1997]. JCN measures the word pairs' informational distance from one another, or their semantic similarities. Therefore, a low JCN score demonstrates a close semantic relationship. Additionally, we can use a measure of semantic feature overlap to examine the semantic relatedness between word pairs [@Buchanan2013; @McRae2005; @Vinson2008], and this measure is factorally related to JCN as a semantic measure [@Maki2008]. Another useful database, created by @Nelson2004, is centered on the associative relationships between words. Participants were given cue words and asked to write the first word that came to mind. These responses were asked of and averaged over many participants. The probability of a cue word eliciting the target word is called the forward strength (FSG). For example, when participants are shown the word *lost*, the most common response is *found*, which has a FSG of .75 or occurs about 75% of the time. 
  
##Separating Semantic and Associative Priming

A meta-analytic review from @Lucas2000 examined semantic priming in the absence of association. Effect sizes for semantic priming alone were lower than associative priming. However, with the addition of an associative relationship to an existing semantic relationship, priming effects nearly doubled, also known as the associative boost [@Moss1995]. This result suggests that semantic relationships, that concurrently have associations, can increase priming effects. Priming effects, therefore, are suggested not to be based on association in isolation. @Hutchison2003 argues against Lucas, suggesting positive evidence for associative priming. Automatic priming was sensitive to associative strength as well as feature overlap. These points of contention provide impetus for more research centering on distinctions between associative and semantic priming.  
  
With the databases described above, orthogonal word pair stimuli can be created to examine associative and semantic priming individually and indeed, priming can be found for each relation separately [@Buchanan2010]. Few studies have directly compared associative and semantic relationships, especially focusing on the brain. @Deacon2004 claim that hemispheric differences exist in lexico-semantic representation, comparing associative and semantic priming. Deacon et al. concluded that semantic features are localized in the right hemisphere, whereas association is localized more within the left hemisphere of the brain. The current study, with an aim to elaborate on basic theoretical questions such as the relationship between associative and semantic processing,  examined the relationship between N400 activation, priming task, and word relationship type. Participants were given both a single lexical decision and letter search task, along with separate semantic, associative, and unrelated word pairs. We expected that the N400 modulation might vary from the different types of word relation, which would indicate differences in c ognitive processing and word organization.
  
#Method

##Participants

Twenty undergraduate students were recruited from the University of Mississippi (thirteen women and seven men), and all volunteered to participate. All participants were English speakers. The experiment was carried out with the permission of the University's Institutional Review Board, and all participants signed corresponding consent forms. One participant's data was corrupted and could not be used, and another participant was excluded for poor task performance (below chance), leaving eighteen participants (twelve women and six men).
  
##Apparatus

The system used was a 32 Channel EEG Cap connected to a NuAmps monopolar digital amplifier, which was connected to a computer running SCAN 4.5 software to record the data. The SCAN software was capable of managing continuous digital data captured by the NuAmps amplifier. STIM2 was used to coordinate the timing issues associated with Windows operating system and collecting EEG data on a separate computer. STIM2 also served as the software base for programming and operating experiments of this nature. The sensors in the EEG cap were sponges injected with 130 ml of electrically conductive solution (non-toxic and non-irritating). Also, to protect the participants and equipment, a surge protector was used at all times during data acquisition. The sensors recorded electrical activity just below the scalp, displaying brain activation. This data was amplified by the NuAmps hardware, and processed and recorded by the SCAN software.
  
##Materials

This experiment consisted of 360 word pairs separated into levels in which the target words were unrelated to the prime (120), semantically associated to the prime (60), associatively related to the prime (60), or were nonwords (120). We used only a small number of related word pairs to try to reduce expectancy effects described in the introduction [@Neely1991]. These 360 pairs were split evenly between the lexical decision and letter search task, therefore, each task contained 60 unrelated pairs, 30 semantically related pairs, 30 associatively related pairs, and 60 nonword pairings. The ratio of yes/no correct answers for words and nonwords in the lexical decision task was 2:1 and 1:1 yes/no decisions in the letter search task. Splitting the nonword pairs over both the letter search and lexical decision task created a higher yes/no ratio for the lexical decision task, which was controlled for by mixing both tasks together.
  
The stimuli were selected from the @Nelson2004 associative word norms and @Maki2004 semantic word norms. The associative word pairs were chosen using the criteria that they were highly associatively related, having an FSG score greater than .50; with little or no semantic similarities, determined by having a JCN score of greater than 20. An example of an associative pair would be *dairy-cow*. The semantic word pairs were chosen using the criteria that they had a high semantic relatedness shown in a JCN of 3 or less; and were not associatively related, having an FSG of less than .01 (e.g., *inn-lodge*). The unrelated words were chosen so that they had no similarities (were unpaired in the databases), such as *blender* and *compass.* For non-word pairs, the target word had one letter changed so that it no longer represented a real word, yet the structure was left intact to require that the participant process the word cognitively. Essentially, non-words were orthographically similar to its real word counterpart, except for the change in a single letter. For example, the word *pond* can be changed to *pund* to produce a non-word target. All materials and their database values can be found at our Open Science Foundation page: https://osf.io/h5sd6/.
  
##Procedure

Testing occurred in one session consisting of six blocks of acquired data, broken up by brief rest periods. Before each participant was measured, the system was configured to the correct settings, and the hardware prepared. Two reference channels, which define zero voltage, were placed on the right and left mastoid bones. 
  
We modeled the current task after @Smith2001 lexical decision and letter search task combination. @Smith2001 used a choice task procedure, where the color of the target word indicated the target task. One color denoted lexical decision with another color denoting letter search. The lexical decision task involved participants observing a word onscreen and deciding whether or not it was a word or non-word (such as *tortoise* and *werm*). Nonrelated word pairs were created by taking prime and target words from related pairs and randomly rearranging them to eliminate relationships between primes and targets. The letter search task involved participants observing a word onscreen and deciding whether it contained a repeated letter or not (i.e. the repeated letters in *doctor* versus no repeated letters in *nurse*). Words were presented onscreen, and would stay there until the participant pressed the corresponding keys for yes and no. Participant responses were time limited and truncated to 60 seconds. The 1 and 9 keys were used on the number row of the keyboard, in the participant's lap to help eliminate muscle movement artifact in the data. 
  
Participants were first given instructions on how to perform the lexical decision task, followed by 15 practice trials. Next, they were given instructions on how to judge the letter search task, followed by 15 practice trials. Participants were then given a practice session with both letter search and lexical decision trials mixed together. Trials were color coded for the type of decision participants had to complete (i.e. letter search was green, while lexical decision was red). The experiment made use of six sets of 60 randomly assigned word pairs for a total of 360 trials. These trials were presented in Arial 19-point font, and the inter-trial interval was set to two  seconds to allow complete recording of the N400 waveform. Trials were recorded in five minute blocks, and between blocks participants were allowed to rest to prevent fatigue. The current task differed from @Smith2001 in that participants responded to every word (prime and targets), instead of only targets. Therefore, there was no typical fixed stimulus onset asynchrony (SOA) because participant responses were self-paced. 
  
#Results

##N400 Waveform Analysis

###Data Screening and Analysis Plan

The data were cleared of artifact data using EEGLAB, an open source MATLAB tool for processing electrophysiological data. The program automatically scanned for and removed artifacts caused by eye-blinking. Next, the datasets were visually inspected and any remaining corrupted sections were removed manually. Ninety percent of the data was retained across all trials and stimulus types after muscular artifact data were removed. However, a loss rate of 20-30 percent is not uncommon, especially with older EEG systems. The data were combined by task and stimulus type exclusively for the second word in each pair. Five sites were chosen to examine priming for nonwords, associative and semantic word pairs based on a survey of the literature. Fz, FCz, Cz, CPz, and Pz were used from the midline. Oz was excluded due to equipment problems across all participants. Using MATLAB, the N400 area under the curve was calculated for each electrode site, stimulus, and task (averaging over trials) around 300-500 msec after stimuli presentation. A constant score was subtracted from all EEG points to ensure all curves were below zero for area under the curve calculations.  

```{r area-DS, include=FALSE}
##import data
curve <- read.csv("area curve.csv")
##Non-Recursive Procedure with Moving Criterion
## 15 = 2.326  20 = 2.391  average equals 2.3585

#melt
longdata = melt(curve,
                id = c("site", "type", "task"), 
                measured = c("X1","X2","X3","X4","X5","X6",
                             "X7","X8","X9","X10","X11",
                             "X12","X13","X14","X15","X16",
                             "X17","X18"))
colnames(longdata) = c("site","type","task","partno", "curve")

table(longdata$type)
longdata$type=factor(longdata$type,
                     levels = c("unrelated","nonword","semantic","assoc"))


##non recursive outliers
zscore = unsplit(lapply(split(longdata$curve, list(longdata$partno, longdata$task)),
                        scale),list(longdata$partno, longdata$task))
summary(abs(zscore) < 2.3585) ##4 outliers
noout = subset(longdata, abs(zscore) < 2.3585) ##exclude outliers

##other data screening
random = rchisq(nrow(noout), 7)
fake = lm(random~., data=noout[, -4])
standardized = rstudent(fake)

#linear
{qqnorm(standardized)
abline(0,1)}

#normal
hist(standardized, breaks=15)

##homogeneity and homoscedaticity
fitvalues = scale(fake$fitted.values)
{plot(fitvalues, standardized) 
abline(0,0)
abline(v = 0)}

```

@VanSelst1994 describes outlier elimination procedures can be affected by factors such as sample size or data skewness. They, as well as @Miller1991, describe procedures for adaptive outlier criteria based on sample size to correct for this any bias due to sample size. We utilized a non-recursive procedure with a moving criterion for outlier elimination. For example, traditional outlier identification may be based on a *z*-score criteria of two or more standard deviations away from the mean score. In the @VanSelst1994, this cut-off *z*-score is adjusted by sample size, and therefore, we used the average of their recommendations for 15 to 20 participants, $z_{critical}$ = 2.36. The non-recursive procedure involves only examing the data once for outliers, rather than continuing to screen for outliers iteratively until no outliers remained. Across 18 participants by five sites, four outlying data points were identified and subsequently removed from further analysis. Data were also screened for parametric assumptions of linearity, normality, homogeneity, and homoscedasticity. The data were slightly negatively skewed, but with the large quantity of data for each participant as well as the choice of analysis, test statistics should be robust to this slight skew.

To analyze this data, we used multilevel models (MLM) to control for correlated error due to repeated measures of sites and stimulus type for each participant [@Gelman2006]. These models were calculated using the *nlme* package in *R* [@Pinheiro2017]. First, a model with only the intercept was compared to a model with participants as a random intercept factor. Random intercepts allow each participant to have different average scores for areas under the curve or peak latency (see below). If the random intercept model was better than the intercept only model, then all forthcoming models would include participants as a random intercept factor. Models were compared only to the previous step and were deamed "significant" if the likelihood ratio difference score, $\Delta\chi^2$ was greater than to be expected given the change in degrees of freedom between models. Therefore, the *p*-values for each $\Delta\chi^2$ were calculated based on $\Delta df$, and $\alpha$ was set to .05. The two tasks, lexical desicion and letter search, were analyzed in separate models with the area under the curve as the dependent variable. The independent variables included the dummy coded site location as a control variable, followed by stimulus type coded as a dummy variable. In this analysis, we wished to compare each stimulus type to every other stimulus type, and therefore, we set $\alpha$ for these six comparisons to .05/6 = .008. The stimuli variable was recoded to examine all pairwise comparisons. 

###Lexical Decision Task

```{r area-LDT, include = FALSE}
##split on task
LDT = subset(noout, task == "ldt")

####ldt models####
LDTmodel1 = gls(curve ~ 1, 
                data = LDT, method = "ML", 
                na.action = "na.omit")

LDTmodel2 = lme(curve ~ 1, 
                data = LDT, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

LDTmodel3 = lme(curve ~ site + type, 
                data = LDT, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

LDToverall = anova(LDTmodel1, LDTmodel2, LDTmodel3)

levels(LDT$type)
LDT$type2 = factor(LDT$type,
                  levels = c("nonword", "unrelated", "semantic", "assoc"))

LDTmodel3.1 = lme(curve ~ site + type2, 
                data = LDT, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

LDT$type3 = factor(LDT$type,
                  levels = c("semantic", "nonword", "unrelated", "assoc"))

LDTmodel3.2 = lme(curve ~ site + type3, 
                data = LDT, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

```

```{r graph-LDT, echo=FALSE,  fig.cap = "SOMETHING SOMETHING HERE", fig.height=8, fig.width=8}

#overall data
graph_data = read.csv("graph_data.csv")
colnames(graph_data)[1:3] = c('Task','Stimuli','Site')
graph_data$Task = factor(graph_data$Task)
graph_data$Stimuli = factor(graph_data$Stimuli)
graph_data$Site = factor(graph_data$Site)
longdata = melt(graph_data,
                   id = c('Task','Stimuli','Site'))
longdata$variable = as.numeric(longdata$variable)

#individual sites data 
ldt_dat = subset(longdata, Task == 'LDT')
lst_dat = subset(longdata, Task == 'LST')
cpz_ldt = subset(ldt_dat, Site == 'CPZ')
cz_ldt = subset(ldt_dat, Site == 'CZ')
fcz_ldt = subset(ldt_dat, Site == 'FCZ')
fz_ldt = subset(ldt_dat, Site == 'FZ')
pz_ldt = subset(ldt_dat, Site == 'PZ')
cpz_lst = subset(lst_dat, Site == 'CPZ')
cz_lst = subset(lst_dat, Site == 'CZ')
fcz_lst = subset(lst_dat, Site == 'FCZ')
fz_lst = subset(lst_dat, Site == 'FZ')
pz_lst = subset(lst_dat, Site == 'PZ')

##ldt graphs
cpz_ldt_g = ggplot(data=cpz_ldt, aes(x=variable, y = value, group = Stimuli)) + 
  geom_line(aes(color=Stimuli,linetype=Stimuli), size=1) +
  scale_linetype_manual(values=c("solid","22","22","solid")) +
  scale_color_manual(values=c('black','gray48','black','gray60')) +
  scale_y_continuous(name = 'Amplitude', limits = c(-2,6)) +
  scale_x_discrete(name = 'CPz', limits = c(175,350,525,700)) +
  geom_hline(yintercept = 0) +
  theme
cz_ldt_g = ggplot(data=cz_ldt, aes(x=variable, y = value, group = Stimuli)) + 
  geom_line(aes(color=Stimuli,linetype=Stimuli), size=1) +
  scale_linetype_manual(values=c("solid","22","22","solid")) +
  scale_color_manual(values=c('black','gray48','black','gray60')) +
  scale_y_continuous(name = 'Amplitude', limits = c(-2,6)) +
  scale_x_discrete(name = 'Cz', limits = c(175,350,525,700)) +
  geom_hline(yintercept = 0) +
  theme
fcz_ldt_g = ggplot(data=fcz_ldt, aes(x=variable, y = value, group = Stimuli)) + 
  geom_line(aes(color=Stimuli,linetype=Stimuli), size=1) +
  scale_linetype_manual(values=c("solid","22","22","solid")) +
  scale_color_manual(values=c('black','gray48','black','gray60')) +
  scale_y_continuous(name = 'Amplitude', limits = c(-2,6)) +
  scale_x_discrete(name = 'FCz', limits = c(175,350,525,700)) +
  geom_hline(yintercept = 0) +
  theme
fz_ldt_g = ggplot(data=fz_ldt, aes(x=variable, y = value, group = Stimuli)) + 
  geom_line(aes(color=Stimuli,linetype=Stimuli), size=1) +
  scale_linetype_manual(values=c("solid","22","22","solid")) +
  scale_color_manual(values=c('black','gray48','black','gray60')) +
  scale_y_continuous(name = 'Amplitude', limits = c(-2,6)) +
  scale_x_discrete(name = 'Fz', limits = c(175,350,525,700)) +
  geom_hline(yintercept = 0) +
  theme
pz_ldt_g = ggplot(data=pz_ldt, aes(x=variable, y = value, group = Stimuli)) + 
  geom_line(aes(color=Stimuli,linetype=Stimuli), size=1) +
  scale_linetype_manual(values=c("solid","22","22","solid")) +
  scale_color_manual(values=c('black','gray48','black','gray60')) +
  scale_y_continuous(name = 'Amplitude', limits = c(-2,6)) +
  scale_x_discrete(name = 'Pz', limits = c(175,350,525,700)) +
  geom_hline(yintercept = 0) +
  theme
temp = ggplot(data=pz_ldt, aes(x=variable, y = value, group = Stimuli)) + 
  geom_line(aes(color=Stimuli,linetype=Stimuli), size=1) +
  scale_linetype_manual(values=c("solid","22","22","solid")) +
  scale_color_manual(values=c('black','gray48','black','gray60')) 
mylegend <- get_legend(temp)
ldt_grid = plot_grid(cpz_ldt_g,cz_ldt_g,fcz_ldt_g,
        fz_ldt_g,pz_ldt_g,ncol=2)
ldt_plot = ldt_grid + draw_grob(mylegend, 2/3,0,1/3,0.4)
ldt_plot
```

```{r graph-LST, echo=FALSE,  fig.cap = "SOMETHING SOMETHING HERE", fig.height=8, fig.width=8}
#lst graphs
cpz_lst_g = ggplot(data=cpz_lst, aes(x=variable, y = value, group = Stimuli)) + 
  geom_line(aes(color=Stimuli,linetype=Stimuli), size=1) +
  scale_linetype_manual(values=c("solid","22","22","solid")) +
  scale_color_manual(values=c('black','gray48','black','gray60')) +
  scale_y_continuous(name = 'Amplitude', limits = c(-2,6)) +
  scale_x_discrete(name = 'CPz', limits = c(175,350,525,700)) +
  geom_hline(yintercept = 0) +
  theme
cz_lst_g = ggplot(data=cz_lst, aes(x=variable, y = value, group = Stimuli)) + 
  geom_line(aes(color=Stimuli,linetype=Stimuli), size=1) +
  scale_linetype_manual(values=c("solid","22","22","solid")) +
  scale_color_manual(values=c('black','gray48','black','gray60')) +
  scale_y_continuous(name = 'Amplitude', limits = c(-2,6)) +
  scale_x_discrete(name = 'Cz', limits = c(175,350,525,700)) +
  geom_hline(yintercept = 0) +
  theme
fcz_lst_g = ggplot(data=fcz_lst, aes(x=variable, y = value, group = Stimuli)) + 
  geom_line(aes(color=Stimuli,linetype=Stimuli), size=1) +
  scale_linetype_manual(values=c("solid","22","22","solid")) +
  scale_color_manual(values=c('black','gray48','black','gray60')) +
  scale_y_continuous(name = 'Amplitude', limits = c(-2,6)) +
  scale_x_discrete(name = 'FCz', limits = c(175,350,525,700)) +
  geom_hline(yintercept = 0) +
  theme
fz_lst_g = ggplot(data=fz_lst, aes(x=variable, y = value, group = Stimuli)) + 
  geom_line(aes(color=Stimuli,linetype=Stimuli), size=1) +
  scale_linetype_manual(values=c("solid","22","22","solid")) +
  scale_color_manual(values=c('black','gray48','black','gray60')) +
  scale_y_continuous(name = 'Amplitude', limits = c(-2,6)) +
  scale_x_discrete(name = 'Fz', limits = c(175,350,525,700)) +
  geom_hline(yintercept = 0) +
  theme
pz_lst_g = ggplot(data=pz_lst, aes(x=variable, y = value, group = Stimuli)) + 
  geom_line(aes(color=Stimuli,linetype=Stimuli), size=1) +
  scale_linetype_manual(values=c("solid","22","22","solid")) +
  scale_color_manual(values=c('black','gray48','black','gray60')) +
  scale_y_continuous(name = 'Amplitude', limits = c(-2,6)) +
  scale_x_discrete(name = 'Pz', limits = c(175,350,525,700)) +
  geom_hline(yintercept = 0) +
  theme
lst_grid = plot_grid(cpz_lst_g,cz_lst_g,fcz_lst_g,
                     fz_lst_g,pz_lst_g,ncol=2)
lst_plot = lst_grid + draw_grob(mylegend, 2/3,0,1/3,0.4)

lst_plot
```

###Letter Search Task

```{r area-LST, include = FALSE}
##split on task
LST = subset(noout, task == "lst")

####LST models####
LSTmodel1 = gls(curve ~ 1, 
                data = LST, method = "ML", 
                na.action = "na.omit")

LSTmodel2 = lme(curve ~ 1, 
                data = LST, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

LSTmodel3 = lme(curve ~ site + type, 
                data = LST, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

LSToverall = anova(LSTmodel1, LSTmodel2, LSTmodel3)

levels(LST$type)
LST$type2 = factor(LST$type,
                  levels = c("nonword", "unrelated", "semantic", "assoc"))

LSTmodel3.1 = lme(curve ~ site + type2, 
                data = LST, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

LST$type3 = factor(LST$type,
                  levels = c("semantic", "nonword", "unrelated", "assoc"))

LSTmodel3.2 = lme(curve ~ site + type3, 
                data = LST, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

```

```{r area-table-model, results='asis', echo = FALSE}
tableprint = matrix(NA, nrow = 6, ncol = 7)
tableprint[ , 1] = c("LDT Intercept", "LDT Random Intercept", "LDT Full",
                     "LST Intercept", "LST Random Intercept", "LST Full")
tableprint[ , 2] = c(LDToverall$df, LSToverall$df)
tableprint[ , 3] = c(LDToverall$AIC, LSToverall$AIC)
tableprint[ , 4] = c(LDToverall$BIC, LSToverall$BIC)
tableprint[ , 5] = c(LDToverall$logLik, LSToverall$logLik)
tableprint[ , 6] = c(LDToverall$L.Ratio, LSToverall$L.Ratio)
tableprint[ , 7] = c(LDToverall$`p-value`, LSToverall$`p-value`)

tableprint[ , 3:6] = printnum(as.numeric(tableprint[ , 3:6]), 
                              gt1 = TRUE, zero = TRUE, big.mark="")
tableprint[ , 7] = printnum(as.numeric(tableprint[ , 7]), 
                              gt1 = FALSE, zero = FALSE, digits = 3)

apa_table.latex(as.data.frame(tableprint), 
          align = c("l", rep("c", 6)), 
          caption = "Area under curve model statistics",
          note = "AIC: Aikaike Information Criterion, BIC: Bayesian Information Criterion", 
          escape = FALSE,
          col.names = c("Model", "$df$", "AIC", "BIC", "$\\chi^2$", "$\\Delta\\chi^2$", "$p$"))
```

```{r area-table-est, results='asis', echo = FALSE}
tableprint = matrix(NA, nrow = 20, ncol = 6)
tableprint[ , 1] = c(rep("LDT", 10), rep("LST", 10)) 
tableprint[ , 2] = rep(c("CZ", "FCZ", "FZ", "PZ", "Unrelated - Nonword", 
                     "Unrelated - Semantic", "Unrelated - Associative",
                     "Nonword - Semantic", "Nonword - Associative", 
                     "Semantic - Associative"), 2)
tableprint[1:7 , 3:6] = summary(LDTmodel3)$tTable[-1 , -3]
tableprint[8:9 , 3:6] = summary(LDTmodel3.1)$tTable[7:8 , -3]
tableprint[10 , 3:6] = summary(LDTmodel3.2)$tTable[8 , -3]

tableprint[11:17 , 3:6] = summary(LSTmodel3)$tTable[-1 , -3]
tableprint[18:19 , 3:6] = summary(LSTmodel3.1)$tTable[7:8 , -3]
tableprint[20 , 3:6] = summary(LSTmodel3.2)$tTable[8 , -3]

tableprint[ , 3:5] = printnum(as.numeric(tableprint[ , 3:5]), 
                              gt1 = TRUE, zero = TRUE)
tableprint[ , 6] = printnum(as.numeric(tableprint[ , 6]), 
                              gt1 = FALSE, zero = FALSE, digits = 3)

apa_table(tableprint, 
          align = c("l", rep("c", 6)), 
          caption = "Area under curve model estimates",
          escape = FALSE,
          note = "The site control level was considered CPZ. Degrees of freedom are 334 for lexical decision tasks and 332 for letter search tasks.",
          col.names = c("Task", "Predictor", "$b$", "$SE$", "$t$", "$p$"))

```

##N400 Peak Analysis

```{r Peak-DS, include=FALSE}
##import data
Peak <- read.csv("Peak.csv")
##Non-Recursive Procedure with Moving Criterion
## 15 = 2.326  20 = 2.391  average equals 2.3585
#melt
Peak = Peak[ , -c(1) ]
longdata = melt(Peak,
                id = c("site", "type.1", "task"), 
                measured = c("X1","X2","X3","X4","X5","X6",
                             "X7","X8","X9","X10","X11",
                             "X12","X13","X14","X15","X16",
                             "X17","X18"))
colnames(longdata) = c("site","type","task","partno", "peak")
table(longdata$type)
longdata$type=factor(longdata$type,
                     levels = c("unrelated","nonwords","semantic","associative"))
table(longdata$type)

##non recursive outliers
zscore = unsplit(lapply(split(longdata$peak, list(longdata$partno, longdata$task)),
                        scale),list(longdata$partno, longdata$task))
summary(abs(zscore) < 2.3585) ##see how many outliers
noout = subset(longdata, abs(zscore) < 2.3585) ##exclude outliers
```

```{r Peak-LDT, include = FALSE}
##split on task
LDT = subset(noout, task == "ldt")

####ldt models####
LDTmodel1 = gls(peak ~ 1, 
                data = LDT, method = "ML", 
                na.action = "na.omit")

LDTmodel2 = lme(peak ~ 1, 
                data = LDT, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

LDTmodel3 = lme(peak ~ site + type, 
                data = LDT, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

LDToverall = anova(LDTmodel1, LDTmodel2, LDTmodel3)

levels(LDT$type)
LDT$type2 = factor(LDT$type,
                  levels = c("nonwords", "unrelated", "semantic", "associative"))

LDTmodel3.1 = lme(peak ~ site + type2, 
                data = LDT, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

LDT$type3 = factor(LDT$type,
                  levels = c("semantic", "nonwords", "unrelated", "associative"))

LDTmodel3.2 = lme(peak ~ site + type3, 
                data = LDT, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

```

###Letter Search Task

```{r Peak-LST, include = FALSE}
##split on task
LST = subset(noout, task == "lst")

####LST models####
LSTmodel1 = gls(peak ~ 1, 
                data = LST, method = "ML", 
                na.action = "na.omit")

LSTmodel2 = lme(peak ~ 1, 
                data = LST, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

LSTmodel3 = lme(peak ~ site + type, 
                data = LST, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

LSToverall = anova(LSTmodel1, LSTmodel2, LSTmodel3)

levels(LST$type)
LST$type2 = factor(LST$type,
                  levels = c("nonwords", "unrelated", "semantic", "associative"))

LSTmodel3.1 = lme(peak ~ site + type2, 
                data = LST, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

LST$type3 = factor(LST$type,
                  levels = c("semantic", "nonwords", "unrelated", "associative"))

LSTmodel3.2 = lme(peak ~ site + type3, 
                data = LST, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

```

```{r Peak-table-model, results='asis', echo = FALSE}
tableprint = matrix(NA, nrow = 6, ncol = 7)
tableprint[ , 1] = c("LDT Intercept", "LDT Random Intercept", "LDT Full",
                     "LST Intercept", "LST Random Intercept", "LST Full")
tableprint[ , 2] = c(LDToverall$df, LSToverall$df)
tableprint[ , 3] = c(LDToverall$AIC, LSToverall$AIC)
tableprint[ , 4] = c(LDToverall$BIC, LSToverall$BIC)
tableprint[ , 5] = c(LDToverall$logLik, LSToverall$logLik)
tableprint[ , 6] = c(LDToverall$L.Ratio, LSToverall$L.Ratio)
tableprint[ , 7] = c(LDToverall$`p-value`, LSToverall$`p-value`)

tableprint[ , 3:6] = printnum(as.numeric(tableprint[ , 3:6]), 
                              gt1 = TRUE, zero = TRUE, big.mark="")
tableprint[ , 7] = printnum(as.numeric(tableprint[ , 7]), 
                              gt1 = FALSE, zero = FALSE, digits = 3)

apa_table.latex(as.data.frame(tableprint), 
          align = c("l", rep("c", 6)), 
          caption = "Peak latency model statistics",
          note = "AIC: Aikaike Information Criterion, BIC: Bayesian Information Criterion", 
          escape = FALSE,
          col.names = c("Model", "$df$", "AIC", "BIC", "$\\chi^2$", "$\\Delta\\chi^2$", "$p$"))
```

```{r Peak-table-est, results='asis', echo = FALSE}
tableprint = matrix(NA, nrow = 20, ncol = 6)
tableprint[ , 1] = c(rep("LDT", 10), rep("LST", 10)) 
tableprint[ , 2] = rep(c("CZ", "FCZ", "FZ", "PZ", "Unrelated - Nonword", 
                     "Unrelated - Semantic", "Unrelated - Associative",
                     "Nonword - Semantic", "Nonword - Associative", 
                     "Semantic - Associative"), 2)
tableprint[1:7 , 3:6] = summary(LDTmodel3)$tTable[-1 , -3]
tableprint[8:9 , 3:6] = summary(LDTmodel3.1)$tTable[7:8 , -3]
tableprint[10 , 3:6] = summary(LDTmodel3.2)$tTable[8 , -3]

tableprint[11:17 , 3:6] = summary(LSTmodel3)$tTable[-1 , -3]
tableprint[18:19 , 3:6] = summary(LSTmodel3.1)$tTable[7:8 , -3]
tableprint[20 , 3:6] = summary(LSTmodel3.2)$tTable[8 , -3]

tableprint[ , 3:5] = printnum(as.numeric(tableprint[ , 3:5]), 
                              gt1 = TRUE, zero = TRUE)
tableprint[ , 6] = printnum(as.numeric(tableprint[ , 6]), 
                              gt1 = FALSE, zero = FALSE, digits = 3)

apa_table(tableprint, 
          align = c("l", rep("c", 6)), 
          caption = "Peak latency model estimates",
          escape = FALSE,
          note = "The site control level was considered CPZ. Degrees of freedom are 333 for lexical decision tasks and 313 for letter search tasks.",
          col.names = c("Task", "Predictor", "$b$", "$SE$", "$t$", "$p$"))

```

  *Lexical Decision Task*. After each set was processed as described in the data processing section, a multilevel. These stimuli were then tested with a single sample t-test comparing each processing difference from zero. The following hypotheses were examined. First, non-word pairs may show significantly more negative waveforms (more negative area) due to the need to search the lexicon before a decision can be made. Second, semantic word paris will have significantly positive values because priming will decrease the need to search the mental lexicon. This is more consistent with the view that the N400 indexes initial contact with semantic memory [@Kutas2011]. Third, associative word paris may have significantly different values from unrelated word pairs, but a direction is not predicted. More positive values would indicate automatic activation similar to semantics, while more negative values would indicate a need to search the mental lexicon. Figure 1 depicts the N400 curves for the selected electrode sites, and Table 1 presents t-test values for the following conclusions. Nonwords were not found to be significantly more negative than unrelated word pairs, which may indicate a controlled lexicon search for both types of stimuli. Both associative and semantic N400 attenuation were found across frontal and midline sites, while neither CPz nor associative Pz showed reduction. In Figure 1, associative and semantic N400 waveforms are well above the unrelated word pairs, indicating automatic priming for both types of relatedness, even when stimuli are controlled for opposing relationships. 
  
  *Letter Search Task*. The same five sites were analyzed as the lexical decision task. Again, data were subtracted from unrelated word pairs averages and then compared against zero with single sample t-tests. The following hypotheses were expected. First, ?	Since task demands require a focus at the lexical level, nonword pairings should not show significant differences from unrelated word pairs. However, if word processing is automatic in a letter search task [@Mari-Beffa2005], then nonwords pairs may show more negative waveforms as participants search the lexicon for the word pair. Second, ?	Semantic and associative word pairs may have significantly positive values because priming will decrease the need to search the mental lexicon; however some research literature indicates that letter search tasks eliminate semantic priming [@Smith2001]. Positive values would indicate a priming effect, which is evidence for activation spreading automatically within the mental lexicon. More negative or nonsignficant values would indicate processing at the lexical, but not semantic, level. Figure 2 portrays the N400 waveforms for the letter search task, and Table 2 contains the t-test values for the following conclusions. Although the average nonword waveform appears to be much lower than unrelated waveform at many sites, the variance across subjects was very large, and no significant differences were found. This finding could indicate that ?wordness? did not matter since participants were searching at a lexical level for specific letters. Nearly all sites showed significant associative and semantic attenuation for the N400 waveform, semantic Cz being the only exception. In comparison, this result seems to suggest that letter search does not inhibit automatic activation of word meaning and association. The nonsignificant relationship between nonwords and unrelated word pairs could be either statistical power or a controlled search process, regardless of task demands.
  
##Task Performance
  Task data were analyzed for correctness in the lexical decision and letter search tasks individually. Error rates were tested with a 2X4 (task by stimulus) repeated measures ANOVA. Overall, performance in the letter search task (M=.97, SD=.02) was equal to the lexical decision task (M=.97, SD=.02), F(1,13)=1.54, p=.24. The interaction between task type and stimuli was also not significant F(3,39)=1.74, p=.18. The different types of stimuli showed a difference in performance, F(3,39)=9.85, p<.001, between nonwords (M=.94, SD=.03, t(13)=-3.02, p=.01) and unrelated word pairs (M=.97, SD=.01); nonwords and associative word pairs (M=.98, SD=.01, t(14)=-5.55, p<.001); and nonwords and semantic word pairs (M=.98, SD=.02, t(14)=-3.45, p=.01). The other stimuli comparisons were all non-significant, and averages by task can be provided upon request.
  
##Reaction Time Performance

```{r RT-DS, include=FALSE}
##import data
Task <- read.csv("task.csv")
##Non-Recursive Procedure with Moving Criterion
## 15 = 2.326  20 = 2.391  average equals 2.3585
longdata = melt(Task,
                 id = c("task","type"), 
                 measured = c("X1","X2","X3","X4","X5","X6",
                              "X7","X8","X9","X10","X11",
                              "X12","X13","X14","X15","X16",
                              "X17","X18"))
colnames(longdata) = c("task","type","partno","RT")
longdata$type=factor(longdata$type,
                     levels = c("UR","NW","LH","HL"),
                     labels = c("unrelated", "nonwords", "semantic", "associative"))

##non recursive outliers
zscore = unsplit(lapply(split(longdata$RT, list(longdata$partno, longdata$task)),
                        scale),list(longdata$partno, longdata$task))

summary(abs(zscore) < 2.3585) ##see how many outliers
noout = subset(longdata, abs(zscore) < 2.3585) ##exclude outliers
```

```{r RT-LDT, include = FALSE}
##split on task
LDT = subset(noout, task == "LDT")

####ldt models####
LDTmodel1 = gls(RT ~ 1, 
                data = LDT, method = "ML", 
                na.action = "na.omit")

LDTmodel2 = lme(RT ~ 1, 
                data = LDT, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

LDTmodel3 = lme(RT ~ type, 
                data = LDT, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

LDToverall = anova(LDTmodel1, LDTmodel2, LDTmodel3)

levels(LDT$type)
LDT$type2 = factor(LDT$type,
                  levels = c("nonwords", "unrelated", "semantic", "associative"))

LDTmodel3.1 = lme(RT ~ type2, 
                data = LDT, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

LDT$type3 = factor(LDT$type,
                  levels = c("semantic", "nonwords", "unrelated", "associative"))

LDTmodel3.2 = lme(RT ~ type3, 
                data = LDT, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)
```

```{r task-LST, include = FALSE}
##split on task
LST = subset(noout, task == "LST")

####LST models####
LSTmodel1 = gls(RT ~ 1, 
                data = LST, method = "ML", 
                na.action = "na.omit")

LSTmodel2 = lme(RT ~ 1, 
                data = LST, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

LSTmodel3 = lme(RT ~ type, 
                data = LST, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

LSToverall = anova(LSTmodel1, LSTmodel2, LSTmodel3)

levels(LST$type)
LST$type2 = factor(LST$type,
                  levels = c("nonwords", "unrelated", "semantic", "associative"))

LSTmodel3.1 = lme(RT ~ type2, 
                data = LST, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

LST$type3 = factor(LST$type,
                  levels = c("semantic", "nonwords", "unrelated", "associative"))

LSTmodel3.2 = lme(RT ~ type3, 
                data = LST, method = "ML", 
                na.action = "na.omit",
                random = ~1|partno)

```

```{r RT-table-model, results='asis', echo = FALSE}
tableprint = matrix(NA, nrow = 6, ncol = 7)
tableprint[ , 1] = c("LDT Intercept", "LDT Random Intercept", "LDT Full",
                     "LST Intercept", "LST Random Intercept", "LST Full")
tableprint[ , 2] = c(LDToverall$df, LSToverall$df)
tableprint[ , 3] = c(LDToverall$AIC, LSToverall$AIC)
tableprint[ , 4] = c(LDToverall$BIC, LSToverall$BIC)
tableprint[ , 5] = c(LDToverall$logLik, LSToverall$logLik)
tableprint[ , 6] = c(LDToverall$L.Ratio, LSToverall$L.Ratio)
tableprint[ , 7] = c(LDToverall$`p-value`, LSToverall$`p-value`)

tableprint[ , 3:6] = printnum(as.numeric(tableprint[ , 3:6]), 
                              gt1 = TRUE, zero = TRUE, big.mark="")
tableprint[ , 7] = printnum(as.numeric(tableprint[ , 7]), 
                              gt1 = FALSE, zero = FALSE, digits = 3)

apa_table.latex(as.data.frame(tableprint), 
          align = c("l", rep("c", 6)), 
          caption = "Response latency model statistics",
          note = "AIC: Aikaike Information Criterion, BIC: Bayesian Information Criterion", 
          escape = FALSE,
          col.names = c("Model", "$df$", "AIC", "BIC", "$\\chi^2$", "$\\Delta\\chi^2$", "$p$"))
```

```{r RT-table-est, results='asis', echo = FALSE}
tableprint = matrix(NA, nrow = 12, ncol = 6)
tableprint[ , 1] = c(rep("LDT", 6), rep("LST", 6)) 
tableprint[ , 2] = rep(c("Unrelated - Nonword", 
                     "Unrelated - Semantic", "Unrelated - Associative",
                     "Nonword - Semantic", "Nonword - Associative", 
                     "Semantic - Associative"), 2)
tableprint[1:3 , 3:6] = summary(LDTmodel3)$tTable[-1 , -3]
tableprint[4:5 , 3:6] = summary(LDTmodel3.1)$tTable[3:4 , -3]
tableprint[6 , 3:6] = summary(LDTmodel3.2)$tTable[4 , -3]

tableprint[7:9 , 3:6] = summary(LSTmodel3)$tTable[-1 , -3]
tableprint[10:11 , 3:6] = summary(LSTmodel3.1)$tTable[3:4 , -3]
tableprint[12 , 3:6] = summary(LSTmodel3.2)$tTable[4 , -3]

tableprint[ , 3:5] = printnum(as.numeric(tableprint[ , 3:5]), 
                              gt1 = TRUE, zero = TRUE)
tableprint[ , 6] = printnum(as.numeric(tableprint[ , 6]), 
                              gt1 = FALSE, zero = FALSE, digits = 3)

apa_table(tableprint, 
          align = c("l", rep("c", 6)), 
          caption = "Peak latency model estimates",
          escape = FALSE,
          note = "Degrees of freedom are 2863 for lexical decision tasks and 2880 for letter search tasks.",
          col.names = c("Task", "Predictor", "$b$", "$SE$", "$t$", "$p$"))

```

  Reaction time data were excluded for incorrect trials. Average reaction times were calculated for each task type and stimulus. The @VanSelst1994 3 standard deviation outlier trimmer procedure was used to eliminate very long reaction times. Next, associative, semantic, and nonword conditions were subtracted from their matching unrelated word conditions. Figure 4 depicts the priming differences for each condition. Each stimulus difference was analyzed with a single sample t-test against zero to examine for priming. 
  
  *Letter Search Task*. All conditions in the letter search task were significantly primed over unrelated words pairs, while nonwords were significantly slower than unrelated word pairs. As shown in Figure 4, associative words pairs were almost 200 msecs faster than unrelated word pairs, t(17) = 3.54, p < .01, and semantic word pairs were also around 200 msecs faster than unrelated word pairs, t(17) = 6.38, p<.01. Nonwords were significantly slower than unrelated word pairs by about 200 msecs, t(17) = -5.18, p<.01. Given previous research, it was slightly surprising that semantic word pairs would be primed during a letter search task, however, the current word list has also shown this effect in @Buchanan2010, and this effect matches N400 results. 
  
  *Lexical Decision Task*. Priming was found for associative word pairs in the lexical decision task, a marginal effect semantic word pairs, and slowing for non-word pairs when compared to unrelated word pairs. Associations were about 120 msecs faster than unrelated word pairs, t(17) = 2.99, p<.01. Semantic word pairs were primed approximately 85 msecs over unrelated pairs, which approached significance, t(17) = 1.93, p=.07. Semantic priming was expected in the lexical decision task, and this effect was most likely due to our small sample size. Nonwords were again 200 msecs slower than unrelated word pairs, t(17) = -5.24, p<.01. 
  
#Discussion
  These experiments were designed to explore the differences between N400 activation in the brain following presentation of semantic-only, associative-only, and unrelated word pairs in priming tasks. The N400 data and reaction time data present picture of associative and semantic priming during both lexical decision and letter search task. Because both tasks were designed to reduce controlled processing of cue-target relationships, these findings imply automatic activation of word meanings and associations, even when task demands do not warrant word activation. Nonword activation is more problematic to interpret, as N400 waveforms are not different from unrelated word pairs, but reaction time data is much slower. These results, taken together, may illustrate a controlled process search of the lexicon requiring the same activation levels. When an unrelated target word is found in the lexicon, controlled search is terminated, while searching for a nonword continues for more time before the search is terminated. However, @Deacon2000 point to potential issues with the relationship between the N400 and automaticity. Semantic processing, @Deacon2000 discuss, is possible in the absence of attention or a dearth of awareness. 
  
  Since findings were roughly similar for associative and semantic word pairs, we can postulate that the activation processes for these types of word relatedness are also roughly similar. This experiment cannot separate if the cognitive architecture is different for associations and semantics, but that the automatic mechanisms for priming are comparable. One limitation is that the long stimulus onset times may have allowed for controlled processing in the reaction time data, but the consistent N400 attenuation suggests a quick search of the lexicon similar to an automatic activation process. Finally, differences in activation across gender need to be explored. Although not conclusive due to sample size, we found that male activation across stimuli was implicated  in traditional left Broca?s area, while female activation averaged to central parietal areas. Regardless of any potential differences, the broad sensitivity of the N400 means it can be implemented when investigating how information is stored in the brain. The temporal lobe has been shown to be implicated as a source from the N400, albeit occurs in a flexible manner, varying with different classes of stimuli [@Federmeier2009]. There are sometimes dissociations between the N400 and reaction time measures. The use of the N400 can therefore be seen as an especially relevant dependent measure for the reason that components can only partially be a reflection of semantic processes relating to response latencies [@Kutas2011]. 
  
  To date, research has focused on semantic priming and its automaticity without many controls for associative relationships embedded in word pairs. Certainly there is overlap between meaning and context use of words, but these differences can be studied separately using available databases [@Hutchison2003]. Our current study has supported findings by @Mari-Beffa2005, who showed activation during letter search tasks, along with the many studies on automatic activation during masked priming [@Deacon2000;@Kiefer2002].
  
  Limitations do exist within these experiments. As previously mentioned a larger sample size would increase the power coefficient of the findings. Future studies should focus on the extent of priming in semantic word pairs during a letter search task, which is a controversial topic within the literature. Since our study limited relatedness to associations or semantics, upcoming experiments could examine the interaction between word relationship type of N400 attenuation. @Kreher2006 have shown that N400 waveform differences can be attributed to different strengths of semantic relatedness in a linear fashion. With more exploration into the exact priming nature of associations and semantics, we may begin to discover their cognitive mechanisms.
  

\newpage

# References

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
